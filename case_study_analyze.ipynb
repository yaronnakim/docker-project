{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seeing-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "import datetime\n",
    "import sys\n",
    "import logging\n",
    "from pyspark import SQLContext, SparkContext, SparkConf\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import col, date_trunc\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType, StructField, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amber-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static variables\n",
    "URL_METADATA = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Movies_and_TV.json.gz'\n",
    "URL_RATING = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Movies_and_TV.csv'\n",
    "RATING_SCHEMA=  StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", IntegerType(), True),\n",
    "    StructField(\"overall\", StringType(), True),\n",
    "    StructField(\"unixReviewTime\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-thirty",
   "metadata": {},
   "source": [
    "### create the full data frame for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|     asin|    reviewerID|overall|unixReviewTime|_corrupt_record|      brand|          categories|         description|               imUrl|price|             related|           salesRank|               title|\n",
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|739476564| AQ692HPAKVW5D|    5.0|    1360886400|           null|       null|[[Movies & TV, Mo...|Nelson Demille: B...|http://ecx.images...| null|                null|[,,,,,, 363116,,,...|Nelson Demille:  ...|\n",
      "|767008650|A1G74RV52LHY1D|    5.0|     925776000|           null|       null| [[Movies & TV, TV]]|Robbie Coltrane r...|http://ecx.images...| null|                null|[,,,,,, 708265,,,...|More Cracker Myst...|\n",
      "|767804236|A25QS83NZP7RUT|    4.0|     959558400|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High|\n",
      "|767804236| AI788E3QP9QP9|    5.0|    1347235200|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High|\n",
      "|767804236|A2MW2RAYI76SSK|    3.0|    1350432000|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High|\n",
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def download_and_create_dataframe():\n",
    "    spark_context = SparkContext.getOrCreate(SparkConf()) \n",
    "    spark_context.addFile(URL_METADATA)\n",
    "    spark_context.addFile(URL_RATING)\n",
    "    sql_context = SQLContext.getOrCreate(spark_context)\n",
    "    #\n",
    "    # after succefull downloading the CSV and JSON i set the logs to ERROR level only\n",
    "    # to reduse the many INFO logs\n",
    "    #\n",
    "    log4j = spark_context._jvm.org.apache.log4j\n",
    "    log4j.LogManager.getRootLogger().setLevel(log4j.Level.ERROR)\n",
    "    \n",
    "    ratings_df = sql_context.read.schema(RATING_SCHEMA).csv(\"file://\"+ SparkFiles.get(\"ratings_Movies_and_TV.csv\"), header=False, inferSchema= True)\n",
    "    metadata_df = sql_context.read.json(\"file://\"+SparkFiles.get(\"meta_Movies_and_TV.json.gz\"))\n",
    "    return ratings_df.join(metadata_df, on = ['asin']), sql_context\n",
    "\n",
    "df,sql_context = download_and_create_dataframe()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hollow-angle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-----------+\n",
      "|     asin|    reviewerID|overall|unixReviewTime|_corrupt_record|      brand|          categories|         description|               imUrl|price|             related|           salesRank|               title|review_date|\n",
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-----------+\n",
      "|739476564| AQ692HPAKVW5D|    5.0|    1360886400|           null|       null|[[Movies & TV, Mo...|Nelson Demille: B...|http://ecx.images...| null|                null|[,,,,,, 363116,,,...|Nelson Demille:  ...| 2013-02-15|\n",
      "|767008650|A1G74RV52LHY1D|    5.0|     925776000|           null|       null| [[Movies & TV, TV]]|Robbie Coltrane r...|http://ecx.images...| null|                null|[,,,,,, 708265,,,...|More Cracker Myst...| 1999-05-04|\n",
      "|767804236|A25QS83NZP7RUT|    4.0|     959558400|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High| 2000-05-29|\n",
      "|767804236| AI788E3QP9QP9|    5.0|    1347235200|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High| 2012-09-10|\n",
      "|767804236|A2MW2RAYI76SSK|    3.0|    1350432000|           null|LOVITZ,JOHN|[[Movies & TV, Mo...|From the creators...|http://ecx.images...| 6.99|[[B004P7CMZ0, B00...|[,,,,,, 33966,,,,,,]|    High School High| 2012-10-17|\n",
      "+---------+--------------+-------+--------------+---------------+-----------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recive dataFrame, clean the data\n",
    "# Input: dataFrame\n",
    "# Outpot: dataFrame\n",
    "\n",
    "def clean_data(df):\n",
    "    # add a date column from the unixReviewTime column\n",
    "    df = df.withColumn('review_date', F.from_unixtime('unixReviewTime').cast(DateType()))\n",
    "    # remove no null corrupt records\n",
    "    df = df.filter(df['_corrupt_record'].isNull())\n",
    "    # filter title with null\n",
    "    df = df.filter(df['title'].isNotNull())\n",
    "    # select only Movies , Movies & TV category from the category column\n",
    "    # use explode to open the array and select only that categories\n",
    "    df = df.withColumn('explode_categories', F.explode(df['categories']))\n",
    "    df = df.withColumn('category', F.explode(df['explode_categories']))\n",
    "    df = df.filter(df['category'].isin('Movies','Movies & TV'))\n",
    "    # use distinct to remove duplicates\n",
    "    df = df.drop('explode_categories','category').distinct()\n",
    "    \n",
    "    return df\n",
    "\n",
    "clean_df = clean_data(df)\n",
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "posted-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recive 1 month dataframe \n",
    "# Input: dataFrame , date\n",
    "# Outpot: dataFrame in the corresponding date\n",
    "def get_one_month(df,date):\n",
    "    start = datetime.date(date.year, date.month,1)\n",
    "    end   = start + datetime.timedelta(days = 31)\n",
    "    end   = datetime.date(end.year, end.month,1)\n",
    "    \n",
    "    return df.filter(F.col('review_date').between(start,end))\n",
    "\n",
    "one_month_df = get_one_month(clean_df, datetime.date(2012, 9, 15))\n",
    "one_month_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amazing-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recive 2 following month dataframe \n",
    "# Input: dataFrame , date\n",
    "# Outpot: dataFrame in the corresponding date\n",
    "def get_two_following_months(df,date):\n",
    "    start = datetime.date(date.year, date.month,1)\n",
    "    end   = start + datetime.timedelta(days = 62)\n",
    "    end   = datetime.date(end.year, end.month,1)\n",
    "    \n",
    "    return df.filter(F.col('review_date').between(start,end))\n",
    "\n",
    "two_month_df = get_two_following_months(clean_df, datetime.date(2012, 9, 15))\n",
    "two_month_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for anelize and present the first question\n",
    "\n",
    "def top_bottom(df,date):\n",
    "    df  = get_one_month(df,date)\n",
    "  \n",
    "    df = df.groupby('asin','title').agg(\n",
    "        F.avg(F.col('overall')).alias('avg_rating'),\n",
    "        F.count(F.col('overall')).alias('count_rating')\n",
    "    ) \n",
    "    top_5_ratings = df.orderBy(F.col('avg_rating').desc(),F.col('count_rating').desc()).limit(5)\n",
    "    buttom_5_ratings = df.orderBy(F.col('avg_rating').asc(),F.col('count_rating').desc()).limit(5)\n",
    "\n",
    "    top_5_ratings.show(5,False) \n",
    "    buttom_5_ratings.show(5,False)\n",
    "            \n",
    "    \n",
    "top_bottom(clean_df,datetime.date(2012, 9, 15))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "million-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "|     asin|               title|max_avg_difference|avg_rating_previous_month|avg_rating_current_month|\n",
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "|767803434|       Air Force One|               4.0|                      1.0|                     5.0|\n",
      "|790731908|National Lampoon'...| 2.857142857142857|                      1.0|       3.857142857142857|\n",
      "|783235666|The Birds (The Al...|             2.625|                      1.0|                   3.625|\n",
      "|979878985|        Ben's Vortex|               2.5|                      2.0|                     4.5|\n",
      "|790742624|Flight of Dragons...|               2.0|                      1.0|                     3.0|\n",
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function for anelize and present the second question\n",
    "def max_5_avg_diff(df,date,sql_context):\n",
    "    # calcuate the necessary dates for creating two dataframes\n",
    "    start = datetime.date(date.year, date.month,1)\n",
    "    previous_month = start - datetime.timedelta(days = 1)\n",
    "    start_previous_month = datetime.date(previous_month.year, previous_month.month, 1)\n",
    "    date_next_month = start + datetime.timedelta(days = 31)\n",
    "    end_date = datetime.date(date_next_month.year, date_next_month.month,1)\n",
    "    df_1 = get_one_month(df,date)\n",
    "    df_2 = get_one_month(df,start_previous_month)\n",
    "    two_month_df = df_1.union(df_2)\n",
    "    # create a temp view for SQL analysis \n",
    "    two_month_df.createOrReplaceTempView('df')    \n",
    "    result_2 = sql_context.sql(f\"\"\"\n",
    "    with previous_month as \n",
    "    (\n",
    "    SELECT asin,title, avg(overall) as avg_rating_previous_month\n",
    "    from df\n",
    "    where review_date between '{previous_month.strftime('%Y-%m-%d')}' and '{start.strftime('%Y-%m-%d')}'\n",
    "    group by asin,title\n",
    "    ),\n",
    "    current_month as\n",
    "    (\n",
    "    SELECT asin,title, avg(overall) as avg_rating_current_month\n",
    "    from df\n",
    "    where review_date between '{start.strftime('%Y-%m-%d')}' and '{end_date.strftime('%Y-%m-%d')}'\n",
    "    group by asin,title\n",
    "    )\n",
    "    SELECT c.asin , c.title, abs(c.avg_rating_current_month - p.avg_rating_previous_month) as max_avg_difference\n",
    "        , p.avg_rating_previous_month, c.avg_rating_current_month\n",
    "    FROM previous_month as p join current_month as c\n",
    "        on p.asin=c.asin and p.title=c.title\n",
    "    WHERE c.avg_rating_current_month > p.avg_rating_previous_month\n",
    "    order by max_avg_difference desc\n",
    "    LIMIT 5\n",
    "    \"\"\")\n",
    "\n",
    "    result_2.show(5)\n",
    "    \n",
    "max_5_avg_diff(clean_df,datetime.date(2012, 9, 15),sql_context)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-volunteer",
   "metadata": {},
   "source": [
    "# main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thermal-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------------------+----------+------------+\n",
      "|asin     |title                                     |avg_rating|count_rating|\n",
      "+---------+------------------------------------------+----------+------------+\n",
      "|790731010|Chariots of Fire                          |5.0       |14          |\n",
      "|783240171|Out of Africa                             |5.0       |10          |\n",
      "|783225849|Psycho (Collector's Edition)              |5.0       |10          |\n",
      "|982449267|Qigong Strength Training                  |5.0       |9           |\n",
      "|783107986|The World At War - 9 Volume Gift Set [VHS]|5.0       |8           |\n",
      "+---------+------------------------------------------+----------+------------+\n",
      "\n",
      "+----------+--------------------------------------------------------+----------+------------+\n",
      "|asin      |title                                                   |avg_rating|count_rating|\n",
      "+----------+--------------------------------------------------------+----------+------------+\n",
      "|792838424 |Runaway Train                                           |1.0       |2           |\n",
      "|1404974571|Bewitched                                               |1.0       |1           |\n",
      "|790749912 |Any Given Sunday                                        |1.0       |1           |\n",
      "|792556364 |Biology Video: Plant Adaptation DVD with Teacher's Guide|1.0       |1           |\n",
      "|1935127268|Dahn Yoga Essentials DVD: Featuring Brain Wave Vibration|1.0       |1           |\n",
      "+----------+--------------------------------------------------------+----------+------------+\n",
      "\n",
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "|     asin|               title|max_avg_difference|avg_rating_previous_month|avg_rating_current_month|\n",
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "|767803434|       Air Force One|               4.0|                      1.0|                     5.0|\n",
      "|790731908|National Lampoon'...| 2.857142857142857|                      1.0|       3.857142857142857|\n",
      "|783235666|The Birds (The Al...|             2.625|                      1.0|                   3.625|\n",
      "|979878985|        Ben's Vortex|               2.5|                      2.0|                     4.5|\n",
      "|790742624|Flight of Dragons...|               2.0|                      1.0|                     3.0|\n",
      "+---------+--------------------+------------------+-------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input: date string\n",
    "# Output: 3 tables: for the given month\n",
    "#         1 - top 5 avg movies reviews \n",
    "#         2 - bottom 5 avg movies reviews \n",
    "#         3 - 5 movies whose average monthly ratings increased the most compared with the previous month\n",
    "def main(argv):\n",
    "    date = datetime.datetime.strptime(argv[1], '%Y-%m-%d').date()\n",
    "    df,sql_context = download_and_create_dataframe()\n",
    "    df = clean_data(df)   \n",
    "    top_bottom(df,date)   \n",
    "    max_5_avg_diff(df,date,sql_context)\n",
    "\n",
    "sys.argv = ['', '2012-09-15']\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-designation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
